# -*- coding: utf-8 -*-
#By: Michael Riviello

'''
Attributes to analyze:
    Pure Analysis: 
        1. Threat Types and Attack Vectors on those types
        2. Defense Mechanisms used based on the Attack Vector showing how often different methods are used on different attacks
        3. Average reaction times of each defense mechanism on attack (box and whisker)
        4. Show monetary loss and data loss based on time and 3 aspects of attacks
            Hypothesis: Time taken to resolve an attack effects the financial and data loss in a positive correlation
    Machine Prediction Analysis:
        1. Predict the number of attacks in the next year after the data (2025) total
        2. Predict what amount of each type of attack will occur in that year
        3. Predict how many of these attacks will occur in each country (or X most common countries + Other)
        or
        1. Show trend of financial and data loss for a/some types of attack
        2. Predict loss for each in following year(s)
'''

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


#ML imports. This might be messy
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import Ridge
from sklearn.preprocessing import PolynomialFeatures


BAR_WIDTH = 0.3


#Function code is a combination of other users code they implemented to check the dataset for missing data and duplicates
def prelim_check(df):
    missing = df.isnull().sum()
    missing_percentage = (missing/len(df))*100
    report = pd.DataFrame({'Missing Count': missing, 'Missing %': missing_percentage})
    if (missing > 0).any():
        print('\nMissing Values Report:')
        print(report[report['Missing Count'] > 0])
    
    dupe_ct = df.duplicated().sum()
    if dupe_ct > 0:
        print(f'\nNumber of duplicate rows: {dupe_ct}')
        
    if (missing == 0).all() and dupe_ct == 0:
        print('Dataset is fully populated and no dupes detected')
    

#creates the 3 sets of bargraphs from section PA4
#Added colors parameter to make sure items have consistent coloring in their bars with prior graphs
def create_affect_graph(df, colors=None):
    fig, (ax, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16,12)) #Graphs will be side-by-side
    col1 = df.columns[0] #The Financial Lost Column
    col2 = df.columns[1] #The Users Affected Column
    
    #Financial Graph
    ax.bar(df.index, df[col1], width=BAR_WIDTH, color=colors)
    ax.set_xlabel(df.index.name)
    ax.set_ylabel(col1)
    ax.bar_label(ax.containers[0], fontsize=8)
    
    #User Graph
    ax2.bar(df.index, df[col2]/100000000, width=BAR_WIDTH, color=colors)
    ax2.set_xlabel(df.index.name)
    ax2.set_ylabel(col2 + ' (in Hundreds of Millions)')
    ax2.bar_label(ax2.containers[0], fontsize=8)
    
    plt.suptitle('Total Financial Loss and User Impact')
    plt.show()
    
'''
Precondition: dataframe sent in has the 4 graph columns (vuln/attack, time, financial, users)
creates the linegraphs showing loss vs time. 
Monetary boolean is used to make either financial loss or user affected the y axis. vuln boolean checks if graph will be vulnerability data or attack data
Added colors parameter to make sure items have consistent coloring in their bars with prior 
Added Machine Learning call to show trendlines while still showing the individual points
'''
def create_mean_LvT_graph(df, colors=None, vuln: bool=True, monetary: bool=True):
    if vuln:
        types = vuln_types
        c = 2
        t = 'Vulnerability'
    else:
        types = atk_types
        c = 3
        t = 'Attack'
    if monetary:
        y = 'Financial Loss (in Million $)'
        title = f'Financial Loss Over Time per {t} Type'
    else:
        y = 'Number of Affected Users'
        title = f'Users Affected Over Time per {t} Type'
    fig, axes = plt.subplots(c,2, figsize=(16,12))
    axes = axes.flatten()
    
    for i, kind in enumerate(types):
        ax = axes[i]
        
        #dataframe made of only rows of associated vulnerability
        subset = df[df.iloc[:, 0] == kind]
        
        #Preparing data for the machine to train on and use to find the line of best fit
        X_raw = subset['Incident Resolution Time (in Hours)']
        y_raw = subset[y]
        X_smooth, y_smooth = poly_regress(X_raw, y_raw, degree=4)
        
    
        ax.plot(X_smooth, y_smooth, color=colors[i], label='Smoothed Fit')                 #Shows the line of best fit generated by the machine
        ax.scatter(X_raw, y_raw, color=colors[i], alpha=0.5, marker='o', label='Raw Data') #Shows the scatterplot of all points
    
        ax.set_title(f'{kind}') #Set subplot name to name of current type
        ax.set_xlabel('Resolution Time (Hours)')
        ax.set_ylabel(f'{y}')
        if monetary:
            ax.set_yticks(range(25,80,5))
        else:
            ax.set_yticks(range(200000, 800001, 100000))

    plt.suptitle(title, fontsize=16)
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    plt.show()

'''
Performs polynomial regression on dataset. Helper function called by create_mean_LvT_graph
checks if X is a series and reshapes it if so. 
I'm a little unsure if this is the best way, or even right despite seeming to work, so any feedback here would be appreciated
'''
def poly_regress(X_raw, y_raw, degree=2):
    if len(X_raw.shape) == 1:
        X = X_raw.values.reshape(-1,1)
    else:
        X = X_raw
    
    y = y_raw.values
    
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.1))
    model.fit(X,y)
    
    X_plot = np.linspace(X.min(), X.max(), 200).reshape(-1,1)
    
    y_pred = model.predict(X_plot)
    
    return X_plot.ravel(), y_pred

if __name__ == "__main__":
    df = pd.read_csv('Global_Cybersecurity_Threats_2015-2024.csv')
    #print(df)
    prelim_check(df)
    
    #PA1: Threat x Attack graph -> Stacked Bargraph to show total and broken parts
    #Lists with the different types of vulnerabiltiies, attacks, and defenses and color palettes that represent each list through all graphs
    vuln_types = sorted(df['Security Vulnerability Type'].unique()) #4
    vuln_colors = sns.color_palette('Set2', n_colors=len(vuln_types))
    atk_types = sorted(df['Attack Type'].unique()) #6 
    atk_colors = sns.color_palette('tab10', n_colors=len(atk_types))
    def_types = sorted(df['Defense Mechanism Used'].unique()) #5
    def_colors = sns.color_palette("viridis", n_colors=len(def_types))
    
    #Makes a dataframe with rows of the unique Vuln Types and Cols being each Attack Type. Cells are the amount of that type of attack on that specific vulnerability
    vuln_atks = df.groupby('Security Vulnerability Type')['Attack Type'].value_counts().unstack()
   
    #Note: Bottoms need to be a cumulative calculation, not just based on the previous bar
    #Building the stacked bar graph
    fig, ax = plt.subplots(figsize = (12,6))
    cumulative = vuln_atks[atk_types].cumsum(axis=1)
    ax.bar(vuln_atks.index, vuln_atks['DDoS'], label='DDoS', width=BAR_WIDTH)
    for i in range(1, len(atk_types)):
        current = atk_types[i]
        below=atk_types[:i]
        ax.bar(
            vuln_atks.index,
            vuln_atks[current],
            bottom=cumulative[below].iloc[:, i-1], #also works as [:,-1], more index error proof with i
            label=current,
            width=BAR_WIDTH
        )
        
    #adding totals above bars
    totals = vuln_atks[atk_types].sum(axis=1)
    for idx, total in enumerate(totals):
        ax.text(idx, total + 2, str(int(total)), ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.02), frameon=True)
    ax.set_yticks(range(0,800,20), minor=True)
    ax.grid(axis='y')
    ax.set_axisbelow(True)
    plt.title('Types of Attacks per Threat Type', fontsize=14, weight='bold')
    plt.xlabel('Vulnerabilities')
    plt.ylabel('# of Attacks (per type)')
    plt.show()
    
    
    #PA2: Defense x Attack graph -> 6 Subplots each showing defense usage on each attack
    
    #Dataframe with rows of defense mechanisms and cols of each attack type. Cells are amount of matchups between attacks and defenses
    atks_defs = df.groupby('Defense Mechanism Used')['Attack Type'].value_counts().unstack().reindex(def_types[::-1])
    
    #Building the subplots of vertically aligned horizontal bar graphs
    fig, ax = plt.subplots(nrows=6, ncols=1, sharex=True, figsize=(16,12))
    d_colors = dict(zip(def_types, def_colors))
    for i in range (0,6):
        current = atk_types[i]
        bar_colors = [d_colors[d] for d in atks_defs.index]
        ax[i].barh(
            atks_defs.index,
            atks_defs[current],
            label=current,
            color = bar_colors
        )
        ax[i].set_ylabel(current, fontweight='bold')
        ax[i].grid(axis='x')
        ax[i].set_axisbelow(True)
    fig.suptitle('Defense Mechanisms Used Against Recorded Attack Types', fontsize=30, fontweight='bold')
    plt.xticks(ticks=range(0,120,5))
    plt.tight_layout()
    plt.show()
    
    #PA(1-2).2 Pie charts showing Threat, Attack and Defense normalized occurance (Scrapped)
    #Code to grab the organized numeric data of vulnerabilities, attacks, and defenses. Assertions to make sure no data is missed in the groupings
    '''
    vuln_total = df.groupby('Security Vulnerability Type').size()
    atk_total = df.groupby('Attack Type').size()
    def_total = df.groupby('Defense Mechanism Used').size()
    
    plt.pie(vuln_total)
    plt.show()
    plt.pie(atk_total)
    plt.show()
    plt.pie(def_total)
    plt.show()
    '''
    
    #PA3 Average response times to attacks and from defenses (2 Box & Whisker Graphs)
    sns.boxplot(
        data=df,
        x='Incident Resolution Time (in Hours)',
        y='Security Vulnerability Type',
        hue='Security Vulnerability Type',
        hue_order=vuln_types,
        order=vuln_types,
        palette=vuln_colors,
        legend=False
        )
    plt.xticks(ticks=range(0,75,5))
    plt.title('Time Taken for Attacks on Vulnerabilities to be Resolved')
    plt.grid(axis='x')
    plt.show()
    
    sns.boxplot(
        data=df,
        x='Incident Resolution Time (in Hours)',
        y='Attack Type',
        hue='Attack Type',
        hue_order=atk_types,
        order=atk_types,
        palette=atk_colors,
        legend=False
        )
    plt.xticks(ticks=range(0,75,5))
    plt.title('Time Taken for Types of Attacks to be Resolved')
    plt.grid(axis='x')
    plt.show()
    
    sns.boxplot(
        data=df,
        x='Incident Resolution Time (in Hours)',
        y='Defense Mechanism Used',
        hue='Defense Mechanism Used',
        hue_order=def_types,
        order=def_types,
        palette=def_colors,
        legend=False
        )
    plt.xticks(ticks=range(0,75,5))
    plt.title('Time Taken for Defense Mechanism to Resolve Attacks')
    plt.grid(axis='x')
    plt.show()
    
    
    #PA4 Finanicials + Users affected for Vulnerability, Attack, and Defense Types
    #Double bar chart for totals, scatter plots w/ trendlines that form a double line plot w/ the lines being the average losses over time
    #Note for double subplots: Make different ax variables to affect 1 plot, use plt to affect graph as a whole (title, show, etc)
    
    #Bar Graphs
    # Vulnerability
    '''vuln_fin_loss = df.groupby('Security Vulnerability Type')['Financial Loss (in Million $)'].sum()
    vuln_affect = df.groupby('Security Vulnerability Type')['Number of Affected Users'].sum()
    Above was applied to both attack and defenses before the below was implemented'''
    vuln_impact = pd.concat([
        df.groupby('Security Vulnerability Type')['Financial Loss (in Million $)'].sum(),
        df.groupby('Security Vulnerability Type')['Number of Affected Users'].sum()],
        axis=1) #puts both commented out dataframes above together without needing those lines + variables as a middle step
    create_affect_graph(vuln_impact, vuln_colors)
    
    # Attack
    atk_impact = pd.concat([
        df.groupby('Attack Type')['Financial Loss (in Million $)'].sum(),
        df.groupby('Attack Type')['Number of Affected Users'].sum()],
        axis=1)
    create_affect_graph(atk_impact, atk_colors)
    
    # Defense
    def_impact = pd.concat([
        df.groupby('Defense Mechanism Used')['Financial Loss (in Million $)'].sum(),
        df.groupby('Defense Mechanism Used')['Number of Affected Users'].sum()],
        axis=1)
    create_affect_graph(def_impact, def_colors)
    
    
    #Averaging
    #Creates a dataframe with multi-level ordering by Vuln type then resolution time. Means all losses and users affected at each Vuln at such time.
    #Vuln
    vuln_time_impact = df.groupby(
        ['Security Vulnerability Type', 'Incident Resolution Time (in Hours)']
        )[['Financial Loss (in Million $)', 'Number of Affected Users']].mean()
    vuln_time_impact = vuln_time_impact.reset_index() #This moves the multi-level grouping from indicies into columns
    
    create_mean_LvT_graph(vuln_time_impact, vuln_colors)
    create_mean_LvT_graph(vuln_time_impact, vuln_colors, monetary=False)
    
    #Atk
    atk_time_impact = df.groupby(
        ['Attack Type', 'Incident Resolution Time (in Hours)']
        )[['Financial Loss (in Million $)', 'Number of Affected Users']].mean()
    atk_time_impact = atk_time_impact.reset_index()
    
    create_mean_LvT_graph(atk_time_impact, atk_colors, vuln=False)
    create_mean_LvT_graph(atk_time_impact, atk_colors, vuln=False, monetary=False)
    
    #Def not used here as the graphs would not show the prevented damage as the data does not have a total in terms of money/users
    
    #The above line graphs disprove the presented hypothesis commented at the top of the program